{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RAG Agent for PDF Documents\n\n",
        "Question-answering system for PDF documents using RAG.\n\n",
        "Features:\n",
        "- Load PDF documents\n",
        "- Extract text and metadata\n",
        "- Create searchable vector index\n",
        "- Query with natural language\n",
        "- Get answers with sources"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, sys\n",
        "from dotenv import load_dotenv\n",
        "sys.path.append('..')\n",
        "load_dotenv()\n\n",
        "from Python_RAG_Agent.data_loader import load_pdf_documents\n",
        "from Python_RAG_Agent.Embeddings import get_default_embeddings\n",
        "from Python_RAG_Agent.vector_store import VectorStoreManager"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load PDF documents\n",
        "pdf_docs = load_pdf_documents('../sample_data/pdf_files')\n",
        "print(f'Loaded {len(pdf_docs)} pages from PDFs')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create vector store\n",
        "embeddings = get_default_embeddings()\n",
        "vector_manager = VectorStoreManager(embeddings, chunk_size=1000, chunk_overlap=200)\n",
        "vector_manager.create_vector_store(pdf_docs)\n",
        "vector_manager.save('../data_storage/vector_store')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build Q&A chain\n",
        "from langchain_anthropic import ChatAnthropic\n",
        "from langchain.chains import RetrievalQA\n\n",
        "llm = ChatAnthropic(model='claude-3-5-sonnet-20241022', temperature=0)\n",
        "retriever = vector_manager.get_retriever(search_kwargs={'k': 3})\n",
        "qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever, return_source_documents=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ask questions\n",
        "question = 'What is the company revenue?'\n",
        "response = qa_chain.invoke({'query': question})\n",
        "print(f'Q: {question}')\n",
        "print(f'A: {response[\"result\"]}')\n",
        "print(f'Sources: {[d.metadata for d in response[\"source_documents\"]]}')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}