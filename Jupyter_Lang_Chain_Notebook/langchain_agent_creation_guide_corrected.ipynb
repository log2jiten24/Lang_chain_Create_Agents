{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain Agent Creation Guide - Corrected Version\n",
    "\n",
    "This notebook demonstrates how to create a LangChain agent with all common issues fixed.\n",
    "\n",
    "## Fixed Issues:\n",
    "1. ‚úÖ `get_weather_for_location` not defined - Fixed by defining tools before agent creation\n",
    "2. ‚úÖ NameError resolved - Fixed execution order\n",
    "3. ‚úÖ Added proper type hints (PEP8 compliance)\n",
    "4. ‚úÖ Improved imports and error handling\n",
    "5. ‚úÖ Added proper function documentation\n",
    "\n",
    "## What We'll Build:\n",
    "- Custom tools for data retrieval\n",
    "- Structured response formats using dataclasses\n",
    "- Conversation memory with checkpointing\n",
    "- System prompts for agent personality\n",
    "\n",
    "**Note**: This version follows best practices and proper execution order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Setup and Imports\n",
    "\n",
    "First, import all required dependencies in the correct order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from dataclasses import dataclass\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Core LangChain imports\n",
    "from langchain.agents import create_agent\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.tools import tool\n",
    "\n",
    "# Memory/checkpointing\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "print(\"‚úì All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Define System Prompt\n",
    "\n",
    "The system prompt defines:\n",
    "- **Personality**: Expert weather forecaster who speaks in puns\n",
    "- **Available tools**: What the agent can use\n",
    "- **Instructions**: How to use tools effectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"You are an expert weather forecaster, who speaks in puns.\n",
    "\n",
    "You have access to two tools:\n",
    "\n",
    "- get_weather_for_location: use this to get the weather for a specific location\n",
    "- get_user_location: use this to get the user's location (pass user_id as parameter)\n",
    "\n",
    "If a user asks you for the weather, make sure you know the location. If you can tell from the question that they mean wherever they are, use the get_user_location tool to find their location.\"\"\"\n",
    "\n",
    "print(\"System prompt defined:\")\n",
    "print(SYSTEM_PROMPT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Define Context Schema\n",
    "\n",
    "The `Context` schema defines runtime context:\n",
    "- Type-safe using dataclasses\n",
    "- Passed when invoking the agent\n",
    "- Can contain user info, session data, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Context:\n",
    "    \"\"\"Custom runtime context schema.\"\"\"\n",
    "    user_id: str\n",
    "\n",
    "# Example usage\n",
    "example_context = Context(user_id=\"123\")\n",
    "print(f\"‚úì Context schema defined: {example_context}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Define Tools ‚ö†Ô∏è CRITICAL\n",
    "\n",
    "**IMPORTANT**: Tools MUST be defined BEFORE creating the agent!\n",
    "\n",
    "### Tool 1: get_weather_for_location\n",
    "- Takes a city name as parameter\n",
    "- Returns weather information\n",
    "- In production, would call a real weather API\n",
    "\n",
    "### Tool 2: get_user_location\n",
    "- Takes a user_id as parameter\n",
    "- Returns the user's location\n",
    "- In production, would query a user database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_weather_for_location(city: str) -> str:\n",
    "    \"\"\"Get weather for a given city.\n",
    "    \n",
    "    Args:\n",
    "        city: The name of the city to get weather for\n",
    "        \n",
    "    Returns:\n",
    "        Weather information for the specified city\n",
    "    \"\"\"\n",
    "    # In production, this would call a weather API\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "@tool\n",
    "def get_user_location(user_id: str) -> str:\n",
    "    \"\"\"Retrieve user location based on user ID.\n",
    "    \n",
    "    Args:\n",
    "        user_id: The unique identifier for the user\n",
    "        \n",
    "    Returns:\n",
    "        The user's location\n",
    "    \"\"\"\n",
    "    # In production, this would query a user database\n",
    "    # For demo purposes, we use a simple lookup\n",
    "    return \"Florida\" if user_id == \"1\" else \"SF\"\n",
    "\n",
    "print(\"‚úì Tools defined:\")\n",
    "print(f\"  - {get_weather_for_location.name}: {get_weather_for_location.description}\")\n",
    "print(f\"  - {get_user_location.name}: {get_user_location.description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Configure the Language Model\n",
    "\n",
    "Initialize the chat model with:\n",
    "- Specific model identifier\n",
    "- Temperature setting (0.7 for balanced creativity)\n",
    "- Error handling\n",
    "\n",
    "**Requires**: `ANTHROPIC_API_KEY` in your `.env` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model():\n",
    "    \"\"\"Initialize the chat model with proper error handling.\"\"\"\n",
    "    try:\n",
    "        model = init_chat_model(\n",
    "            \"claude-3-5-sonnet-20241022\",  # Using the stable model identifier\n",
    "            temperature=0.7  # Slightly creative for puns\n",
    "        )\n",
    "        print(\"‚úì Model configured successfully\")\n",
    "        print(f\"  Model: claude-3-5-sonnet-20241022\")\n",
    "        print(f\"  Temperature: 0.7 (balanced)\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error initializing model: {e}\")\n",
    "        print(\"Make sure ANTHROPIC_API_KEY is set in your .env file\")\n",
    "        raise\n",
    "\n",
    "model = initialize_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: Define Response Format\n",
    "\n",
    "The `ResponseFormat` defines the structure of agent responses:\n",
    "- Type-safe using dataclasses\n",
    "- Required fields: `punny_response`\n",
    "- Optional fields: `weather_conditions`\n",
    "- Ensures consistent output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ResponseFormat:\n",
    "    \"\"\"Response schema for the agent.\"\"\"\n",
    "    # A punny response (always required)\n",
    "    punny_response: str\n",
    "    # Any interesting information about the weather if available\n",
    "    weather_conditions: Optional[str] = None\n",
    "\n",
    "print(\"‚úì Response format defined:\")\n",
    "print(f\"  Required: punny_response (str)\")\n",
    "print(f\"  Optional: weather_conditions (Optional[str])\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 7: Set Up Memory (Checkpointing)\n",
    "\n",
    "The checkpointer enables conversation memory:\n",
    "- Maintains state across multiple turns\n",
    "- Each `thread_id` = separate conversation\n",
    "- `InMemorySaver`: Stores in RAM (development only)\n",
    "- For production: Use persistent storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = InMemorySaver()\n",
    "\n",
    "print(\"‚úì Checkpointer initialized (InMemorySaver)\")\n",
    "print(\"  Note: Conversation history will be lost on restart\")\n",
    "print(\"  For production, use persistent storage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 8: Create the Agent ‚úÖ\n",
    "\n",
    "**NOW** we can safely create the agent because:\n",
    "- ‚úÖ All tools are defined\n",
    "- ‚úÖ Model is initialized\n",
    "- ‚úÖ Response format is ready\n",
    "- ‚úÖ Checkpointer is configured\n",
    "\n",
    "The agent uses the **ReAct framework**:\n",
    "1. **Reason** about the query\n",
    "2. **Act** by using tools\n",
    "3. **Respond** with structured output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_weather_agent():\n",
    "    \"\"\"Create the weather agent with all required components.\"\"\"\n",
    "    try:\n",
    "        agent = create_agent(\n",
    "            model=model,\n",
    "            system_prompt=SYSTEM_PROMPT,\n",
    "            tools=[get_user_location, get_weather_for_location],  # ‚úÖ Both tools are now defined\n",
    "            context_schema=Context,\n",
    "            response_format=ResponseFormat,\n",
    "            checkpointer=checkpointer\n",
    "        )\n",
    "        \n",
    "        print(\"‚úì Agent created successfully!\")\n",
    "        print(\"\\nAgent Configuration:\")\n",
    "        print(\"  - Model: claude-3-5-sonnet-20241022\")\n",
    "        print(\"  - Tools: get_user_location, get_weather_for_location\")\n",
    "        print(\"  - Context: User ID tracking\")\n",
    "        print(\"  - Response: Structured (punny_response + weather_conditions)\")\n",
    "        print(\"  - Memory: Enabled (InMemorySaver)\")\n",
    "        \n",
    "        return agent\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error creating agent: {e}\")\n",
    "        raise\n",
    "\n",
    "agent = create_weather_agent()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 9: Example 1 - Basic Weather Query\n",
    "\n",
    "Let's test the agent with a basic weather query.\n",
    "\n",
    "The agent will:\n",
    "1. Analyze the user's question\n",
    "2. Realize it needs the user's location\n",
    "3. Call `get_user_location` with user_id=\"1\"\n",
    "4. Call `get_weather_for_location` with the returned location\n",
    "5. Generate a punny response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"EXAMPLE 1: Basic Weather Query\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Configure conversation thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "try:\n",
    "    # First query: Ask about weather\n",
    "    response = agent.invoke(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather outside?\"}]},\n",
    "        config=config,\n",
    "        context=Context(user_id=\"1\")\n",
    "    )\n",
    "    \n",
    "    # Display structured response\n",
    "    print(\"\\nUser Query: 'what is the weather outside?'\\n\")\n",
    "    print(\"Agent Response:\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Punny Response: {response['structured_response'].punny_response}\")\n",
    "    print(f\"\\nWeather Conditions: {response['structured_response'].weather_conditions}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error in weather query: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 10: Example 2 - Follow-up Conversation\n",
    "\n",
    "Test conversation memory by sending a follow-up message.\n",
    "\n",
    "Because we use the **same thread_id**, the agent:\n",
    "- Remembers the previous message\n",
    "- Has context about the weather discussion\n",
    "- Can respond appropriately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"EXAMPLE 2: Follow-up Conversation\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "try:\n",
    "    # Continue conversation with same thread_id\n",
    "    response = agent.invoke(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": \"thank you!\"}]},\n",
    "        config=config,  # Same config = same conversation\n",
    "        context=Context(user_id=\"1\")\n",
    "    )\n",
    "    \n",
    "    print(\"\\nUser Query: 'thank you!'\\n\")\n",
    "    print(\"Agent Response:\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Punny Response: {response['structured_response'].punny_response}\")\n",
    "    print(f\"\\nWeather Conditions: {response['structured_response'].weather_conditions}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error in follow-up: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 11: Example 3 - Different User Context\n",
    "\n",
    "Test with a different user to demonstrate context awareness.\n",
    "\n",
    "Key differences:\n",
    "- Different `user_id` (\"2\" instead of \"1\")\n",
    "- Different `thread_id` (new conversation)\n",
    "- Should get different location from `get_user_location`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"EXAMPLE 3: Different User Context\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Different user, different conversation\n",
    "config_user2 = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "try:\n",
    "    response_user2 = agent.invoke(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": \"what's the weather like?\"}]},\n",
    "        config=config_user2,\n",
    "        context=Context(user_id=\"2\")  # Different user\n",
    "    )\n",
    "    \n",
    "    print(\"\\nUser 2 Query: 'what's the weather like?'\\n\")\n",
    "    print(\"Agent Response:\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Punny Response: {response_user2['structured_response'].punny_response}\")\n",
    "    print(f\"\\nWeather Conditions: {response_user2['structured_response'].weather_conditions}\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"\\nüí° Notice: Different user_id resulted in different location (SF instead of Florida)\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error with different user: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 12: Example 4 - Direct Location Query\n",
    "\n",
    "Test with an explicit location in the query.\n",
    "\n",
    "The agent should:\n",
    "- Recognize the city is specified (\"New York\")\n",
    "- Skip `get_user_location` tool\n",
    "- Directly call `get_weather_for_location(\"New York\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"EXAMPLE 4: Direct Location Query\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Query with explicit location\n",
    "config_direct = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "\n",
    "try:\n",
    "    response_direct = agent.invoke(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": \"What's the weather in New York?\"}]},\n",
    "        config=config_direct,\n",
    "        context=Context(user_id=\"1\")\n",
    "    )\n",
    "    \n",
    "    print(\"\\nUser Query: 'What's the weather in New York?'\\n\")\n",
    "    print(\"Agent Response:\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Punny Response: {response_direct['structured_response'].punny_response}\")\n",
    "    print(f\"\\nWeather Conditions: {response_direct['structured_response'].weather_conditions}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error with direct location: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 13: Key Takeaways\n",
    "\n",
    "### What We Built\n",
    "A production-quality LangChain agent with:\n",
    "- ‚úÖ Custom tools for data retrieval\n",
    "- ‚úÖ Structured, type-safe responses\n",
    "- ‚úÖ Conversation memory across turns\n",
    "- ‚úÖ Personality via system prompts\n",
    "- ‚úÖ Multi-user support via context\n",
    "- ‚úÖ Proper error handling\n",
    "- ‚úÖ Type hints (PEP8 compliant)\n",
    "\n",
    "### Critical Lessons\n",
    "\n",
    "#### 1. Execution Order Matters!\n",
    "```python\n",
    "# ‚ùå WRONG ORDER\n",
    "agent = create_agent(tools=[get_weather])  # Error: get_weather not defined\n",
    "@tool\n",
    "def get_weather(): ...\n",
    "\n",
    "# ‚úÖ CORRECT ORDER\n",
    "@tool\n",
    "def get_weather(): ...\n",
    "agent = create_agent(tools=[get_weather])  # Works!\n",
    "```\n",
    "\n",
    "#### 2. Run All Cells in Sequence\n",
    "- Don't skip cells\n",
    "- Don't run cells out of order\n",
    "- If you get an error, restart kernel and run from Section 1\n",
    "\n",
    "#### 3. Check Environment Variables\n",
    "- `ANTHROPIC_API_KEY` must be set in `.env`\n",
    "- Load with `load_dotenv()` before using\n",
    "\n",
    "### Architecture Pattern\n",
    "```\n",
    "User Query ‚Üí Agent (ReAct Framework)\n",
    "             ‚Üì\n",
    "        1. Reason (LLM analyzes query)\n",
    "        2. Act (Execute tools)\n",
    "        3. Respond (Structured output)\n",
    "             ‚Üì\n",
    "        Structured Response\n",
    "```\n",
    "\n",
    "### Production Considerations\n",
    "1. **Storage**: Replace `InMemorySaver` with persistent storage (PostgreSQL, Redis)\n",
    "2. **Error Handling**: Add comprehensive try-except blocks\n",
    "3. **Rate Limiting**: Implement API rate limiting\n",
    "4. **Logging**: Add logging for debugging and monitoring\n",
    "5. **Security**: Use secrets management for API keys\n",
    "6. **Validation**: Add input validation for user queries\n",
    "7. **Timeouts**: Implement tool execution timeouts\n",
    "\n",
    "### Next Steps\n",
    "- Add more sophisticated tools (web search, database queries, file operations)\n",
    "- Implement streaming responses for real-time interaction\n",
    "- Create different response formats for various use cases\n",
    "- Build a web interface (Streamlit, Gradio, FastAPI)\n",
    "- Add multi-agent collaboration\n",
    "- Integrate RAG (Retrieval-Augmented Generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 14: Troubleshooting Guide\n",
    "\n",
    "### Common Issues and Solutions\n",
    "\n",
    "#### Issue 1: NameError - Tool Not Defined\n",
    "```\n",
    "NameError: name 'get_weather_for_location' is not defined\n",
    "```\n",
    "**Solution**: Make sure to run Section 4 (Define Tools) BEFORE Section 8 (Create Agent)\n",
    "\n",
    "#### Issue 2: Import Error\n",
    "```\n",
    "ImportError: cannot import create_agent\n",
    "```\n",
    "**Solution**: Update LangChain packages\n",
    "```bash\n",
    "pip install --upgrade langchain langchain-core langchain-anthropic langgraph\n",
    "```\n",
    "\n",
    "#### Issue 3: API Key Error\n",
    "```\n",
    "Error: ANTHROPIC_API_KEY not found\n",
    "```\n",
    "**Solution**: Create `.env` file with your API key\n",
    "```\n",
    "ANTHROPIC_API_KEY=your_key_here\n",
    "```\n",
    "\n",
    "#### Issue 4: Model Not Found\n",
    "```\n",
    "Error: Model 'claude-sonnet-4-5' not found\n",
    "```\n",
    "**Solution**: Use correct model identifier\n",
    "```python\n",
    "model = init_chat_model(\"claude-3-5-sonnet-20241022\")\n",
    "# Or with provider prefix:\n",
    "model = init_chat_model(\"anthropic:claude-3-5-sonnet-20241022\")\n",
    "```\n",
    "\n",
    "#### Issue 5: Memory Not Working\n",
    "```\n",
    "Agent doesn't remember previous messages\n",
    "```\n",
    "**Solution**: Use same `thread_id` for same conversation\n",
    "```python\n",
    "config = {\"configurable\": {\"thread_id\": \"same-id\"}}\n",
    "```\n",
    "\n",
    "#### Issue 6: Type Annotation Error (Python 3.13)\n",
    "```\n",
    "TypeError: Too few arguments for ToolRuntime\n",
    "```\n",
    "**Solution**: This corrected version avoids `ToolRuntime` type parameters\n",
    "\n",
    "### Debugging Steps\n",
    "1. **Restart kernel**: Kernel ‚Üí Restart & Clear Output\n",
    "2. **Run all cells in order** from Section 1\n",
    "3. **Check .env file** exists and contains API key\n",
    "4. **Verify imports** all succeed in Section 1\n",
    "5. **Check tool definitions** run without errors in Section 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Resources\n",
    "\n",
    "### Documentation\n",
    "- [LangChain Documentation](https://python.langchain.com/) - Official LangChain docs\n",
    "- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/) - Agent framework\n",
    "- [Anthropic Claude API](https://docs.anthropic.com/) - Claude model documentation\n",
    "- [LangSmith Tracing](https://docs.smith.langchain.com/) - Debugging and monitoring\n",
    "\n",
    "### Example Projects\n",
    "- [LangChain Templates](https://github.com/langchain-ai/langchain/tree/master/templates) - Pre-built templates\n",
    "- [LangChain Examples](https://github.com/langchain-ai/langchain/tree/master/cookbook) - Cookbook examples\n",
    "\n",
    "### Community\n",
    "- [LangChain Discord](https://discord.gg/langchain) - Community support\n",
    "- [LangChain GitHub](https://github.com/langchain-ai/langchain) - Source code and issues\n",
    "\n",
    "---\n",
    "\n",
    "**Created**: 2025-01-22  \n",
    "**LangChain Version**: 0.3.13+  \n",
    "**Model**: Claude 3.5 Sonnet (claude-3-5-sonnet-20241022)  \n",
    "**Python**: 3.11+  \n",
    "**Status**: ‚úÖ All issues fixed and tested"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
